### P1090 合并果子

算法标签: **二叉堆**, **优先队列**, **贪心**
其他标签: **NOIp提高组**, **2004**, **高性能**


#### Description

在一个果园里，多多已经将所有的果子打了下来，而且按果子的不同种类分成了不同的堆。多多决定把所有的果子合成一堆。

每一次合并，多多可以把两堆果子合并到一起，消耗的体力等于两堆果子的重量之和。可以看出，所有的果子经过 n-1 次合并之后， 就只剩下一堆了。多多在合并果子时总共消耗的体力等于每次合并所耗体力之和。

因为还要花大力气把这些果子搬回家，所以多多在合并果子时要尽可能地节省体力。假定每个果子重量都为 1 ，并且已知果子的种类 数和每种果子的数目，你的任务是设计出合并的次序方案，使多多耗费的体力最少，并输出这个最小的体力耗费值。

#### Analysis

知道这里可以用贪心算法。但是如何证明贪心算法确实可以得到最优解。

耗费了一天时间，专门找这个问题的答案。

其实这是一个赫夫曼（Huffman) 编码中的关键问题。

#### 赫夫曼编码问题

赫夫曼编码要求： 根据字频进行编码： 字频越高，编码越短； 字频越低，编码可以长一点没关系。

赫夫曼编码可以用一个二叉树构造。每个叶子节点对应一个字符。路径结点对应编码：左0右1。 编码长度即字符节点在树中的深度。

总的编码长度为 ：

$$ABL(T) = \sum_{\text{leaves of T}}{f(x) d(x, T)} $$

其中 $f(x)$ 表示字频， $d(x, T)$ 表示 $x$ 在 树中的深度。

先暂停一下，回到合并果子这个问题上来。 这个问题问：什么样的移动方案可以使总体力最小？

可以随便想象一个方案： 每次都是选择两堆，合并，使得总堆数 - 1。最后得到一个大堆。 跟踪每个小堆的情况，会发现，为了使总耗费体力最小，大的堆被合并的次数越少越好； 小的堆被合并的次数可以多一些。

将这种操作画成一个树形，可以发现就是一颗二叉树。并且优化问题也是一样的。

$$ ABL(T) = \sum_{每堆果子}{w(x)d(x, T)}$$

其中 $w(x)$ 表示每堆重量。 $d(x, T)$ 表示移动的次数，即从底部到根节点的距离，也就是深度。

虽然看不出来赫夫曼编码问题（高大上）和合并果子问题（接地气）之间有什么内在联系，但是二者的优化问题确实是一样的。


#### 赫夫曼编码贪心算法最优解证明

赫夫曼编码使用贪心算法： 每次从字符集 $A$ 中取出两个字频最小的$x, y$，合并形成一个新的节点 $z$， $f(z) = f(x) + f(y)$。 再将 $z$ 放入字符集中，构成新的字符集 $A' = A - \{x, y\} + \{z\}$。 重复此过程，直到字符集只剩下 1个 “字符”，作为根节点。

合并果子问题（真接地气！）也是类似： 每次选择两堆重量最小的合成一堆，然后与剩余的堆一起，重复此过程。


以下引理中出现的 $ABL(T)$，我也不知道 $ABL$ 什么鬼意思，就作为一个符号，表示需要优化的目标。

**Lemma1 交换两个叶子节点 $a, b$ 在树中的位置，得到的新的树 $T'$， $$ABL(T') - ABL(T) = (f(a) - f(b))(d(b, T) - d(a, T))$$**

这个证明很简单。（之前忽略了一件事情，就是主要关心叶子节点。 会发现内部节点的数值会有变化， 但是对优化目标的影响主要通过叶子节点的计算）

**Lemma2 存在一个最优解，其中两个最小字频的节点 $x$ 和 $y$ 是兄弟节点。**

证明： 考虑一个最优解结构 $T$，最深的两个节点是 $a$ 和 $b$，其中 $d(a) = d(b) = max$， 可以假设 $ f(a) \leq f(b)$,  $f(x) \leq f(y)$。 因为 $x$ 和 $y$ 是最小字频的节点，也不难看出 $f(x) \leq f(a), f(y) \leq f(b)$， $d(x) \leq d(a)$， $d(y) \leq d(b)$。

（关于 $f(y) \leq f(b)$ 我纠结了一会，其实 如果 $f(y) > f(b)$ 的话，$x$ 和 $y$ 就不是所谓的最小的两个节点了）


现在将 $a$ 和 $x$ 换一下，得到 $T'$

$$
\begin{align}
ABL(T') &= ABL(T) + (f(a) - f(x))(d(x, T) - d(a, T))\\
&\leq ABL(T)
\end{align}$$

再将 $b$ 和 $y$ ，得到 $T''$
$$
\begin{align}
ABL(T'') &= ABL(T') + (f(b) - f(y))(d(y, T') - d(b, T'))\\
&\leq ABL(T')
\end{align}$$

所以 $ABL(T'') \leq ABL(T') \leq ABL(T)$， 又因为 $T$ 已经是最优结构，所以 $ABL(T'') \geq ABL(T)$， 所以 $ABL(T'') = ABL(T)$


这里可以抬几个杠

1. 如果 $a$ 和 $x$ 的交换，破坏了 $d(y)$ 和 $d(b)$ 的大小关系？ 这只会发生在 $a = y$ 或者 $x = b$ 的时候

首先如果 $f(a) = f(x)$，其实可以认为 $a = x$，不用交换。

如果 $x = b$， 由 $f(x) \leq f(a) \leq f(b)$ 可以知道： $f(x) = f(a) = f(b)$， 所以 $x = a = b$， 也不用交换。

如果 $a = y$， 画个图就可以看出，不要将 $x$ 和 $a = y$ 换， 将 $x$ 和 $b$ 换，也能满足上述不等式。

这个杠可以通过画画图，就能轻松化解掉。

2. 还有一个杠精： 有没有没有兄弟节点的最优解？

答案是没有。 如果一个节点只有一个子节点（child），把这个节点基本上没有什么作用

- 在编码问题中，相当于多了没有任何意义的一位编码。除了增加编码长度没有任何好处。 去掉就能产生一个更好的解。
- 在果子合并问题中，相当于把一堆从一个地方移到另一个地方，除了白瞎了体力，也没有任何好处。


**Lemma3** 贪心算法可以得到最优解。

这里用数学归纳法证明。

$n = 1, 2$ 的时候，很容易看出，没有别的选择。贪心算法是 100% 正确的。

现在假设对于  $n - 1$ 的字符集，贪心算法都能得到最优解。

对于大小为 $n$ 的字符集，现在选择两个最小字频的节点 $x, y$， 合并成 $z$ ，变成一个 $n - 1$ 大小的字符集， 并且具有最优解 $ABL(T')$

可以证明有 $ABL(T) = ABL(T') + f(x) + f(y)$

如果 $T$ 不是最优解结构。 按照 **Lemma2**， 存在一种最优解结构 $Z$， $x$ 和 $y$ 是两个兄弟节点。

将 $Z$ 这两个节点给干掉，得到的 $Z'$ 是与 $T'$ **同样的问题** 的某个解，

$$ \begin{align}
ABL(Z) &= ABL(Z') + f(x) + f(y) \\
< ABL(T) &= ABL(T') + f(x) + f(y)\\
\end{align}$$

所以 $ABL(Z') < ABL(T')$。 这与之前的假设 $T'$ 是最优解 是矛盾的。

所以 大小为 $n$ 的字符集，可以通过贪心选择两个最小字频的节点，组成一个新节点。 重复的方式得到一个最优解。


#### 小结

贪心算法的内在本质仍然是逐渐降低问题规模。

回顾一下《算法导论》笔记

**对一个问题来说，如果它的一个最优解包含了其子问题的最优解，则称该问题具有最优子结构**

这个性质是用来对 动态规划以及贪心算法的可应用性进行评价的关键一点。

贪心算法的证明：

需要证明：问题的最优解 **之一**，具有某种特定结构，这种特定结构是一个特定选择和一个子问题的最优解。（例如赫夫曼编码问题的一个最优解，具有两个最小字频节点位于最深位置的结构）。

1. 也许有其他最优解。但是其他选择 **并不能继续改善** 这个特定结构的 **最优解** ，或者说，调整其他最优解的结构成为这个特定结构，也不会使最优解变坏（ 例如 Lemma 2 中的证明，证明选择是最优选择 ）
2. 证明子问题的最优解 + 贪心选择， 是问题的最优解。 一般用反证。即如果子问题的最优解 + 贪心选择 不是问题的最优解， 得出一个矛盾的结论，例如子问题的这个解不是最优解。（例如 Lemma 3 中的证明）

简化来说：
1. 证明贪心选择可以得到最优解： 其他选择也不会改善最优解的大小。
2. 证明贪心选择 + 子问题的最优解 是问题的最优解。

第一个比较明显； 第二个感觉上似乎有些多余，但是感觉还是必要的。只是感觉。

总的来说，就是证明： 贪心选择 + 子问题的最优解 = 某个最优解



贪心算法的设计模式：

1. 决定问题的最优子结构
2. 设计出一个递归解
3. **证明在递归的任一阶段，最优选择之一总是贪心选择。这样，贪心选择总是安全的，并且可以和剩下的子问题的最优解构成最优解**
4. _证明通过做贪心选择，至多剩下一个子问题_（其他子问题为空？）
5. 设计贪心策略的递归版本
6. 设计迭代版本



#### [Code](../cpp/p1090.cpp)
