

## 并查集（Union/Find Set）

有的书上（算法导论和数据结构）上面叫做 **不相交集合（disjoint set）**。

首先定义说明 **等价** 关系。

**等价关系** （equivalence relation） 是满足下列三个性质的关系 $R$

1. 自反性： 对于所有的 $a \in S$， $aRa$
2. 对称性： $aRb$ 当且仅当 $bRa$
3. 传递性： 若 $aRb$ 且 $bRc$， 则 $aRc$。

比如 电气连通性 就是一个等价关系： 两个元件如果通过导线连接则具有等价性，并且是自反、对称和传递的。

任意无向图中点的连通关系也是一种等价关系：每个连通子图中的点都是 “等价”的：这种连通关系具有自反、对称和传递性。

一个元素 $a\in S$ 的 **等价类** 是 $S$ 的一个子集，它包含所有与 $a$ 有等价关系的元素。

等价类形成对 $S$ 的一个划分： $S$ 的每一个成员都恰好出现在一个等价类中。这样由等价关系划分出来的子集集合 $\{S_1, S_2, \dots, S_n\}$ 彼此之间是 **不相交的**， 这也是 **不相交集合** 名称的来源。

对这种不相交子集集合，有两个最基本的操作

1. 对任意两个元素，判断是否等价关系。
2. 如果两个元素不是等价关系（属于不同等价类），使用 Union 操作，表示将这两个元素建立等价关系，产生的改变就是将两个等价类合并成一个 等价类（根据对称、传递性）。

首先明确，这两个操作的重点不是元素，而是元素所在的等价类。判断元素是否等价关系通过判断两个元素所属等价类是否相同。合并操作也是将元素所属等价类改变。

因此定义下面两个操作：

1. Find 查询元素所属等价类
2. Union 修改不同元素所属等价类，使之相同。

这是 **并查集 (Union/Find Set)** 名字的来源。这两个名字都并不是很直观。

### 简单实现

一种最简单的实现方式是用一个数组保存每个元素所属等价类的标记（id）。需要注意的是，这个id 也可以是任意的，只要能区分等价类即可。

这样 Find 操作只需要 $O(1)$ 时间，但是 Union 操作就很糟糕： 它需要找到其中一个元素等价的其他元素并更新等价类标记。 这需要 $O(N)$ 的时间。

连续 $N - 1$ 次Union操作，需要 $O(N^2)$ 时间。 如果有 $\Omega (N^2)$ 次 Find 操作，那么每次操作的均摊时间就很好，是 $O(1)$ 的。 这里 $\Omega$ 是下界的意思。

如果 Find 操作没有那么多，$O(N^2)$ 这个界是不理想的。

### 简单改进

一种改进是在 `Union(X, Y)` 操作中，将 Y 变成 X 的子树。 `X, Y` 是不同的根，表示元素所属等价类。 

这样在实现 Find 的时候，向上找到元素的根节点就可以了 。

这是以牺牲 Find 效率，来改进 Union的 效率。一种最坏情况是， 在 $N - 1$ 次 Union 操作之后， 变成了一个 高度为 $N$ 的树， 一次 Find 操作需要花费 $O(N)$ 时间。


### 按秩求并

这种策略最大的问题是树的不平衡，导致树的深度太大。有两种非常简单的策略可以改进这一点：

1. 总是让较小的树成为较大的树的子树
2. 总是让较浅的树成为较深的树的子树

这就需要多记录一个树的大小， 或者树的高度。

在这种策略下，可以证明任何节点的深度都不会超过 $\log N$。

证明思路比较巧妙，是一种反向思考。

对任意一个固定的元素 X，深度改变一定发生在较小的集合中。一次Union之后，集合中必定至少有两个元素；二次 Union之后，集合中至少有4个元素；$k$ 次更新后至少有 $2^k$ 个元素。 因此对于 $N$ 个元素，元素 X 最多只有 $\log N$ 次更新。 其深度也不会超过 $\log N$

因此 对于 $N$ 个元素， $M$ 次 Find 操作的最坏情况是 $O(M\log N)$

注意上面证明的时候用的是深度改变。

实际应用实际上用的高度：当两个树的高度相同时，增加一个树根的高度即可，这种操作最少，改变更缓慢。 所以一般采取按高度求并（union-by-height）的策略。（树的高度有时称为 秩， rank， 所以按高度求并也称为按秩求并）。

### 路径压缩

如果 Find 操作非常多， $O(M\log N)$ 也是不理想的。。。

还有一种对于 Find 的改进策略是， 路径压缩： 当找到一个元素的根的时候，将其路径上所有节点的父节点都改成根。

路径压缩不完全与按高度求并兼容，因为路径压缩可以改变树的高度。但是注意： 1. 不影响 Union 操作的效率； 2. 会极大改善 Find 的效率。

单纯只用 路径压缩也是 $O(M\log N)$ 的效率。

但是同时使用两种策略，任意顺序的 $M = \Omega(N)$ 次 Union/Find 操作花费的总的运行时间为 $O(M\log ^*N)$。 $\log^*N$ 是一个增长非常缓慢的函数，意思是不断对一个数 $N$ 做 $\log$ 运算，变成 1 的次数。 其中 $\log^*2^{65536} = 5$， $2^{65536}\sim 10^{19728}$。 

所以可以认为每种操作的均摊时间只有 $O(1)$。

证明如果有兴趣读一读 《数据结构与算法分析》 或者 《算法导论》。 很有趣的证明过程。 没看懂。。


综合考虑，只是用路径压缩是最简单有效的方案。如果追求极致，可以尝试两种策略同时进行。

```cpp
int s[MAX_N];  // 需要初始化

int find(int x)
{
    if (s[x] == x)
        return x;
    return s[x] = find(s[x]);
}

void unite(int x, int y)
{
    s[find(x)] = find(y);
}
```
只是用了路径压缩的策略，代码非常简洁。但是需要多一个 初始化的操作： `s[i] = i`


```cpp
int s[MAX_N] = {0};

int find(int x)
{
    if (s[x] <= 0)
        return x;
    return s[x] = find(s[x]);
}

void unite(int x, int y)
{
    int rx = find(x);
    int ry = find(y);

    if (rx == ry) return;

    if (s[ry] < s[rx]) // y is deeper
        s[rx] = ry;
    else
    {
        if (s[rx] == s[ry])
            s[rx]--;
        s[ry] = rx;
    }
}
```

在这个代码里面， 将根节点和高度都放在了同一个数组里。（参考数据结构与算法分析）。

高度用非正数表示，初始值为0。 

在查找操作中，如果找到非正数，说明找到根了，返回自身。 并使用了 路径压缩策略。

在合并操作中，当两个子树高度相同的时候， 将其中一个子树 X的高度 减 1（更小）， 将另一个子树 Y 的根设置为 X 的根。

当子树 Y 的高度比 X 的高度更负时，其实说明 Y 的高度更高， 将 X 的根设置为 Y 的根即可。

这里还注意一件事情： 合并操作，如果 X 和 Y 的根是相同的，那么说明二者不需要合并，可以直接退出。

如果少了这一步，会内存溢出、发生段错误等事情。 让我找了一阵子bug。 就是在二者相等的时候， 仍然合并了一次，就发生段错误了。



### 并查集的简化版本。

```cpp
struct DisjointSet
{
    int n;
    int s[MAX_N];
    DisjointSet(int n) : n(n)
    {
        for (int i = 0; i <= n; ++i)
            s[i] = i;
    }
    int find(int x)
    {
        if (s[x] == x)
            return x;
        return s[x] = find(s[x]);
    }
    void unite(int x, int y)
    {
        s[find(x)] = find(y);
    }
    bool equivalent(int x, int y)
    {
        return find(x) == find(y);
    }
    int size()
    {
        int _size = 0;
        for (int i = 1; i <= n; ++i)
            if (s[i] == i) ++_size;
        return _size;
    }
    void print()
    {
        for (int i = 1; i <= n; ++i)
            printf("%d ", s[i]);
        printf("\n");
    }
};
```